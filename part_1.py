# -*- coding: utf-8 -*-
"""part 1.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1rcuIo6CbmuQOXlEx6sHkXHkjTDl09Lbh
"""

!pip install yfinance

import yfinance as yf
import pandas as pd

# Define the ticker symbol for Ethereum
ticker_symbol = 'ETH-USD'

# Fetch historical data from Yahoo Finance
eth_data = yf.download(ticker_symbol, start='2020-01-01', end='2024-12-31', interval='1d')

# Reset index to move 'Date' from index to a column
eth_data.reset_index(inplace=True)

# Rename columns to match the required schema
eth_data.rename(columns={
    'Date': 'date',
    'Open': 'open',
    'High': 'high',
    'Low': 'low',
    'Close': 'close',
    'Volume': 'volume'
}, inplace=True)

# Calculate Market Cap as a proxy (Close Price Ã— Volume)
eth_data['market_cap'] = eth_data['close'] * eth_data['volume']

# Reorder columns
eth_data = eth_data[['date', 'open', 'high', 'low', 'close', 'volume', 'market_cap']]

# Save the dataset to a CSV file
eth_data.to_csv('eth_usdt_yahoo_data.csv', index=False)

print("Data collection complete. Dataset saved as 'eth_usdt_yahoo_data.csv'.")

"""DATA CLEANING"""

# 1. Load the dataset
eth_df = pd.read_csv("eth_usdt_yahoo_data.csv")

# 2. Drop the invalid first row if it contains header-like values
if eth_df.iloc[0].str.contains("ETH-USD").any():
    eth_df = eth_df.drop(index=0).reset_index(drop=True)

# 3. Convert 'date' to datetime
eth_df['date'] = pd.to_datetime(eth_df['date'])

# 4. Convert numeric columns to float
for col in ['open', 'high', 'low', 'close', 'volume']:
    eth_df[col] = pd.to_numeric(eth_df[col], errors='coerce')

# 5. Drop rows with any missing values
eth_df.dropna(inplace=True)

# 6. Recalculate market cap as close Ã— volume
eth_df['market_cap'] = eth_df['close'] * eth_df['volume']

# 7. Set 'date' as index and sort
eth_df.set_index('date', inplace=True)
eth_df.sort_index(inplace=True)

# 8. Save cleaned file
eth_df.to_csv("eth_usdt_yahoo_data_cleaned.csv")

"""EXPLORATORY DATA ANALYSIS"""

import pandas as pd
import matplotlib.pyplot as plt

# Load cleaned dataset
df = pd.read_csv("eth_usdt_yahoo_data_cleaned.csv", parse_dates=['date'])
df.set_index('date', inplace=True)
df.sort_index(inplace=True)

# 1. Line plot of closing prices
plt.figure(figsize=(14, 6))
plt.plot(df['close'], color='orange', label='Closing Price')
plt.title("Ethereum Closing Price Over Time")
plt.xlabel("Date")
plt.ylabel("Price (USD)")
plt.grid(True)
plt.legend()
plt.tight_layout()
plt.show()

# 2. Rolling average (30-day)
df['close_rolling'] = df['close'].rolling(window=30).mean()
plt.figure(figsize=(14, 6))
plt.plot(df['close'], alpha=0.4, label='Daily Close')
plt.plot(df['close_rolling'], color='red', label='30-Day Moving Average')
plt.title("Ethereum Closing Price with 30-Day Rolling Average")
plt.xlabel("Date")
plt.ylabel("Price (USD)")
plt.grid(True)
plt.legend()
plt.tight_layout()
plt.show()

# 3. Volume trend
plt.figure(figsize=(14, 4))
plt.plot(df['volume'], color='purple', label='Daily Volume')
plt.title("Ethereum Trading Volume Over Time")
plt.xlabel("Date")
plt.ylabel("Volume (USD)")
plt.grid(True)
plt.legend()
plt.tight_layout()
plt.show()

# 4. Summary statistics
print(df[['open', 'high', 'low', 'close', 'volume', 'market_cap']].describe())

!pip install statsmodels

import pandas as pd
import matplotlib.pyplot as plt
from statsmodels.tsa.stattools import adfuller
from statsmodels.graphics.tsaplots import plot_acf, plot_pacf

# Load dataset if not already loaded
df = pd.read_csv("eth_usdt_yahoo_data_cleaned.csv", parse_dates=['date'])
df.set_index('date', inplace=True)
df.sort_index(inplace=True)

# 1. Plot original series
plt.figure(figsize=(14, 5))
plt.plot(df['close'], label='Closing Price', color='orange')
plt.title("Ethereum Closing Price (Original Series)")
plt.xlabel("Date")
plt.ylabel("Price (USD)")
plt.grid(True)
plt.legend()
plt.tight_layout()
plt.show()

# 2. ADF test on raw data
adf_raw = adfuller(df['close'])
print("ðŸ“Š ADF Test on Raw Data")
print(f"ADF Statistic: {adf_raw[0]}")
print(f"p-value: {adf_raw[1]}")
print("Critical Values:")
for key, val in adf_raw[4].items():
    print(f"   {key}: {val}")

# 3. Differencing
df['diff_close'] = df['close'].diff().dropna()

# 4. Plot differenced series
plt.figure(figsize=(14, 5))
plt.plot(df['diff_close'], label='1st Order Differenced', color='orange')
plt.title("Ethereum Closing Price (1st Order Differenced)")
plt.xlabel("Date")
plt.ylabel("Differenced Price")
plt.grid(True)
plt.legend()
plt.tight_layout()
plt.show()

# 5. ADF test on differenced data
adf_diff = adfuller(df['diff_close'].dropna())
print("\nðŸ“Š ADF Test on Differenced Data")
print(f"ADF Statistic: {adf_diff[0]}")
print(f"p-value: {adf_diff[1]}")
print("Critical Values:")
for key, val in adf_diff[4].items():
    print(f"   {key}: {val}")

# 6. ACF and PACF
fig, axes = plt.subplots(1, 2, figsize=(16, 5))
plot_acf(df['diff_close'].dropna(), ax=axes[0], lags=50)
axes[0].set_title("ACF - Differenced Series")
plot_pacf(df['diff_close'].dropna(), ax=axes[1], lags=50, method='ywm')
axes[1].set_title("PACF - Differenced Series")
plt.tight_layout()
plt.show()

from statsmodels.tsa.arima.model import ARIMA
from statsmodels.graphics.tsaplots import plot_acf, plot_pacf
import warnings

# Suppress convergence warnings
warnings.filterwarnings("ignore")

# Load and prepare the cleaned data
df = pd.read_csv("eth_usdt_yahoo_data_cleaned.csv", parse_dates=['date'])
df.set_index('date', inplace=True)
df.sort_index(inplace=True)

# Step 1: Plot ACF and PACF to determine (p, q)
df['diff_close'] = df['close'].diff().dropna()

fig, axes = plt.subplots(1, 2, figsize=(16, 5))
plot_acf(df['diff_close'].dropna(), ax=axes[0], lags=50)
axes[0].set_title("ACF - Differenced Series")
plot_pacf(df['diff_close'].dropna(), ax=axes[1], lags=50, method='ywm')
axes[1].set_title("PACF - Differenced Series")
plt.tight_layout()
plt.show()

# Step 2: Try different (p,d,q) combinations based on ACF/PACF
order_candidates = [(1,1,1), (2,1,1), (1,1,2), (2,1,2), (3,1,1)]
results = []

for order in order_candidates:
    try:
        model = ARIMA(df['close'], order=order)
        model_fit = model.fit()
        results.append({
            'order': order,
            'aic': model_fit.aic
        })
    except:
        results.append({
            'order': order,
            'aic': None
        })

# Step 3: Select the best model by lowest AIC
results_df = pd.DataFrame(results).dropna().sort_values(by='aic')
best_order = results_df.iloc[0]['order']
print(f"âœ… Best ARIMA Order (p,d,q): {best_order}")

# Step 4: Fit the final model
final_model = ARIMA(df['close'], order=best_order)
final_model_fit = final_model.fit()
print("\nðŸ“˜ Model Summary:")
print(final_model_fit.summary())

# Step 5: Residuals plot
residuals = final_model_fit.resid
plt.figure(figsize=(12, 4))
plt.plot(residuals)
plt.title("Residuals of the Final ARIMA Model")
plt.xlabel("Time")
plt.ylabel("Residuals")
plt.grid(True)
plt.tight_layout()
plt.show()

import numpy as np
from sklearn.metrics import mean_squared_error, mean_absolute_percentage_error
import matplotlib.pyplot as plt

# Load data and refit model if needed
import pandas as pd
from statsmodels.tsa.arima.model import ARIMA

df = pd.read_csv("eth_usdt_yahoo_data_cleaned.csv", parse_dates=['date'])
df.set_index('date', inplace=True)
df.sort_index(inplace=True)

# Fit best ARIMA model (from Task 4: ARIMA(2,1,2))
model = ARIMA(df['close'], order=(2, 1, 2))
model_fit = model.fit()

# Step 1: Predict within-sample (training set)
predicted = model_fit.predict(start=1, end=len(df)-1, typ='levels')

# Step 2: Actual values (shifted for alignment due to differencing)
actual = df['close'].iloc[1:]

# Step 3: Evaluate using RMSE and MAPE
rmse = np.sqrt(mean_squared_error(actual, predicted))
mape = mean_absolute_percentage_error(actual, predicted)

print(f"âœ… RMSE: {rmse:.2f}")
print(f"âœ… MAPE: {mape * 100:.2f}%")

# Step 4: Plot actual vs predicted prices
plt.figure(figsize=(14, 6))
plt.plot(actual, label='Actual Prices', color='orange')
plt.plot(predicted, label='Predicted Prices (In-Sample)', color='blue', alpha=0.7)
plt.title("Actual vs Predicted Prices (Training Set)")
plt.xlabel("Date")
plt.ylabel("Price (USD)")
plt.legend()
plt.grid(True)
plt.tight_layout()
plt.show()

# Step 5: Residuals analysis
residuals = model_fit.resid

plt.figure(figsize=(12, 4))
plt.plot(residuals, color='purple')
plt.title("Model Residuals (Error)")
plt.xlabel("Time")
plt.ylabel("Residual (Error)")
plt.grid(True)
plt.tight_layout()
plt.show()

# Fit the ARIMA(2,1,2) model (from Task 4)
model = ARIMA(df['close'], order=(2, 1, 2))
model_fit = model.fit()

# Forecast next 30 days
forecast_steps = 30
forecast = model_fit.get_forecast(steps=forecast_steps)

# Extract forecast mean and confidence intervals
forecast_mean = forecast.predicted_mean
forecast_ci = forecast.conf_int()

# Create future date index
last_date = df.index[-1]
future_dates = pd.date_range(start=last_date + pd.Timedelta(days=1), periods=forecast_steps)

# Plot historical + forecast
plt.figure(figsize=(14, 6))
plt.plot(df['close'], label='Historical Prices')
plt.plot(future_dates, forecast_mean, label='30-Day Forecast', color='green')
plt.fill_between(future_dates,
                 forecast_ci.iloc[:, 0],
                 forecast_ci.iloc[:, 1],
                 color='lightgreen',
                 alpha=0.4,
                 label='95% Confidence Interval')
plt.title("Ethereum Price Forecast for Next 30 Days (ARIMA)")
plt.xlabel("Date")
plt.ylabel("Price (USD)")
plt.legend()
plt.grid(True)
plt.tight_layout()
plt.show()



"""The ARIMA(2,1,2) model projects Ethereum prices over the next 30 days to remain relatively stable with a slight upward trend. The 95% confidence interval reflects increasing uncertainty over time, which is typical in financial forecasting. The narrow initial interval suggests high model confidence in the short term, while the widening band reflects greater volatility expectations further out"""